{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45a028-6b5f-40f6-9c21-ef9e901d835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 1 \n",
    "\n",
    "'''\n",
    "A z-test is employed when the sample size is relatively large (usually n > 30) or when the population standard deviation (σ) is known. It is primarily used for testing hypotheses about population means (μ) when the population standard deviation is available. The formula for the z-test statistic involves the sample mean (x̄), population mean (μ), population standard deviation (σ), and sample size (n). This test assumes that the population follows a normal distribution or that the sample size is sufficiently large for the Central Limit Theorem to apply. An example scenario for a z-test could be testing whether a new drug's effectiveness differs significantly from a known standard when you have access to the population standard deviation.\n",
    "\n",
    "A t-test is employed when the sample size is small (typically n < 30) or when the population standard deviation (σ) is unknown, necessitating its estimation from the sample data. It is also used for testing hypotheses about population means (μ). The t-test statistic is calculated using the sample mean (x̄), sample standard deviation (s), population mean (μ), and sample size (n). This test assumes that the population from which the sample is drawn follows a normal distribution. An example scenario for a t-test might involve assessing whether a new teaching method significantly improves student performance based on a small sample of students.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8670d-2d72-4493-b253-5ca26de8b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 2\n",
    "\n",
    "'''\n",
    "One-tailed and two-tailed tests are distinct types of statistical hypothesis tests, each serving different research objectives. A one-tailed test, also known as a one-sided test, is employed when the researcher has a specific directional hypothesis in mind. It focuses on determining whether a population parameter is either greater than or less than a certain value, but not both simultaneously. This type of test is characterized by a critical region on one side of the distribution curve, either on the right (indicating \"greater than\") or the left (indicating \"less than\"), based on the direction specified in the research hypothesis. One-tailed tests are suitable when researchers have a strong expectation of the effect's direction.\n",
    "\n",
    "Conversely, a two-tailed test, or two-sided test, is chosen when the research hypothesis does not specify the direction of the expected effect or difference. It is designed to detect whether a population parameter is significantly different from a specified value, irrespective of whether it is greater or less than that value. In a two-tailed test, the critical region is divided into two parts, on both sides of the distribution curve. This allows researchers to assess whether the parameter differs significantly in either direction from the specified value. Two-tailed tests are used when researchers want to remain open to the possibility of the effect being in either direction or when no specific directional expectation exists in their hypothesis.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70048d77-d11a-435d-af88-ea68c7f9d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3\n",
    "\n",
    "'''\n",
    "type 1 error - when we reject the null hyothesis where in reality it  is true\n",
    "\n",
    "type 2 error - we retain the null hypothesis when in reality it is false\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead4767-0070-4765-972f-71b8351c285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 4\n",
    "\n",
    "'''\n",
    "Bayes's theorem is a fundamental concept in probability theory and statistics that helps update our beliefs or probabilities about an event based on new evidence or information. It provides a way to calculate conditional probabilities, which are the probabilities of an event occurring given that another event has already occurred.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870d4e9-cc5b-493e-a195-db0366eba5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 5 \n",
    "\n",
    "'''\n",
    "A confidence interval is a statistical range or interval that provides an estimate of the likely range of values for a population parameter, such as a population mean or proportion, based on a sample of data. It quantifies the uncertainty associated with estimating a parameter and expresses it as a range of values within which we believe the true parameter value is likely to fall, along with a specified level of confidence.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2e6feb-9213-443c-a817-24023c015f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.385903824349676 48.614096175650324\n"
     ]
    }
   ],
   "source": [
    "#question 7\n",
    "\n",
    "import numpy as np \n",
    "import scipy.stats as stats\n",
    "sample_size = 30\n",
    "sample_mean = 50\n",
    "sample_std = 5 \n",
    "confidence_interval = 0.95\n",
    "\n",
    "\n",
    "critcal_value =stats.norm.ppf((1+confidence_interval)/2)\n",
    "\n",
    "margin_of_error = (sample_std * critcal_value)/np.sqrt(sample_mean)\n",
    "\n",
    "lower_bound = sample_mean - margin_of_error\n",
    "upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "print(upper_bound, lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c3473-6fd5-464f-a74f-5b6223feb0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 8 \n",
    "\n",
    "'''\n",
    "The margin of error (MOE) in a confidence interval is a measure of the precision or uncertainty associated with estimating a population parameter, such as the population mean or proportion, based on a sample of data. It quantifies the range within which we expect the true population parameter to fall with a certain level of confidence. The MOE represents the \"wiggle room\" around the point estimate (e.g., the sample mean) and is typically expressed as a positive value. It is calculated by multiplying the critical value (usually derived from a standard normal distribution for means) by the standard error of the sample statistic.\n",
    "\n",
    "Sample size has a significant impact on the margin of error. As the sample size increases, the margin of error tends to decrease. This relationship is because a larger sample provides more information about the population and reduces the uncertainty in the estimate. A larger sample results in a smaller standard error, which, in turn, leads to a narrower confidence interval and a smaller margin of error. In practical terms, this means that if you have a larger sample, you can make more precise statements about the population parameter with the same level of confidence. Conversely, with a smaller sample, the margin of error increases, making your estimate less precise and leaving more room for uncertainty in your inference about the population. Therefore, increasing the sample size is a common strategy to reduce the margin of error in confidence interval estimation when feasible.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5879ab19-1c04-49b1-9209-7623c577b97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#question 9 \n",
    "\n",
    "sample_mean = 70\n",
    "sample_std = 5\n",
    "data_point = 75\n",
    "\n",
    "zscore = (data_point - sample_mean)/sample_std\n",
    "\n",
    "print(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e410227d-5fa0-4572-9eec-ccf9df7fe07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. The drug is significantly effective.\n"
     ]
    }
   ],
   "source": [
    "#question 10 \n",
    "\n",
    "sample_size = 50\n",
    "sample_mean = 6\n",
    "sample_std = 2.5\n",
    "alpha = 0.05\n",
    "popuulation_mean_h0 = 0\n",
    "dof = (sample_size - 1)\n",
    "\n",
    "t_statistics = (sample_mean - popuulation_mean_h0)/(sample_std/np.sqrt(sample_size))\n",
    "\n",
    "critical_value = stats.t.ppf((alpha/2),dof)\n",
    "\n",
    "if (t_statistics) > critical_value:\n",
    "    print(\"Reject the null hypothesis. The drug is significantly effective.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The drug may not be significantly effective.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "270b570c-ab83-4c41-9c8d-51b76fb64f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6081925393809212 0.6918074606190788\n"
     ]
    }
   ],
   "source": [
    "#question 11 \n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import scipy.stats as stats\n",
    "sample_size =500\n",
    "sample_proportion = 0.65\n",
    "confidence_interval = 0.95\n",
    "se = np.sqrt((sample_proportion*(1 - sample_proportion)/sample_size))\n",
    "\n",
    "zscore = stats.norm.ppf((1+confidence_interval)/2)\n",
    "\n",
    "MOE = zscore * se\n",
    "\n",
    "lower_bound = sample_proportion- MOE\n",
    "upper_bound = sample_proportion + MOE\n",
    "\n",
    "print(lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5915a61-0c9f-48be-a807-8cde236f1cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.10319919251691 66.89680080748309\n"
     ]
    }
   ],
   "source": [
    "#question 13\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "p_mean = 60\n",
    "p_std = 8\n",
    "sample_mean = 65\n",
    "sample_size  = 50\n",
    "confidence_interval = 0.9\n",
    "dof = sample_size - 1 \n",
    "\n",
    "zscore = stats.norm.ppf((1+confidence_interval)/2)\n",
    "\n",
    "SE = p_std / np.sqrt(sample_size)\n",
    "\n",
    "t_critical = stats.t.ppf((1+confidence_interval)/2,dof)\n",
    "\n",
    "margin_of_error = t_critical * (SE)\n",
    "confidence_interval_lower = sample_mean - margin_of_error\n",
    "confidence_interval_upper = sample_mean + margin_of_error\n",
    "\n",
    "print(confidence_interval_lower,confidence_interval_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176df262-ef09-4a0c-b311-f846be1e45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 14\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
