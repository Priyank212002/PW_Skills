{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad0ddf-af1e-468b-95e7-720a121d03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 1 \n",
    "\n",
    "\"Min-Max scaling is a data preprocessing technique used to rescale numeric features in a dataset to a specific range, typically between 0 and 1. It's also known as \"normalization\" and is a common method for ensuring that all features have the same scale, which can be important for various machine learning algorithms, such as gradient descent-based methods, k-means clustering, and support vector machines, to perform optimally. Min-Max scaling works by linearly transforming the original feature values into the desired range\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276152b9-2c4c-4ec4-891f-dd73348bfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 2 \n",
    "\n",
    "\"The Unit Vector technique, also known as vector normalization or Feature Scaling by Unit Vector, is another method used for feature scaling in data preprocessing. Unlike Min-Max scaling, which scales features to a specific range (e.g., [0, 1]), the Unit Vector technique scales features to have a unit norm, meaning they are transformed into vectors with a length or magnitude of 1. This technique is particularly useful when the direction of the data points matters more than their actual values. It is commonly used in machine learning algorithms that rely on distance measures, such as k-nearest neighbors (KNN) and support vector machines (SVM)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147daa4-cfda-4f1f-92e6-f5572ac44429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3\n",
    "\n",
    "\"Principal Component Analysis (PCA) is a dimensionality reduction technique commonly used in the field of data analysis and machine learning. Its primary goal is to reduce the number of features (or dimensions) in a dataset while preserving the most important information and structure of the data. PCA achieves this by transforming the original features into a new set of linearly uncorrelated variables called principal components.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2972f-e302-4f7a-a7c1-8445cf968524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 4 \n",
    "\n",
    "\"PCA (Principal Component Analysis) is a dimensionality reduction technique that can also serve as a powerful feature extraction method. Feature extraction is the process of transforming original features into a new, often reduced, set of features while retaining essential information. PCA inherently performs feature extraction as its primary step. It identifies linear combinations of the original features, known as principal components, that maximize the variance in the data. These principal components replace the original features, effectively serving as a new set of features. Although PCA is often associated with dimensionality reduction, it can also be used for other purposes, such as visualization, data denoising, and feature selection. The extracted principal components are designed to capture the most significant information in the data, making PCA a versatile tool for feature extraction in various data analysis and machine learning applications.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee254f-d29f-48c7-8063-5043a0ce402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 5 \n",
    "\n",
    "\" a recommendation system for a food delivery service using a dataset that includes features like price, rating, and delivery time, Min-Max scaling can be a valuable preprocessing step to ensure that these features are on a common scale, typically within the range of [0, 1].\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38b1ee-b6a6-4e87-b469-776676b1394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 6 \n",
    "\n",
    "\"Principal Component Analysis (PCA) to reduce the dimensionality of a dataset in a project aimed at predicting stock prices can be a valuable technique, especially when dealing with a dataset containing numerous features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879af707-a818-4f56-ae5e-1485ae495bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#question 7 \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "l = [[1, 5, 10, 15, 20]]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(l)\n",
    "print(scaler.transform(l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc7fc5-cba9-4ae1-af8c-5418ee60172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
