{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560e986-4b35-4d57-a296-bd65bf0429f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 1  \n",
    "\n",
    "\"R-squared, often denoted as R², is a statistical measure used in linear regression models to assess the goodness of fit of the model to the data. It represents the proportion of the variance in the dependent variable that is explained by the independent variables included in the model. In other words, R-squared quantifies how well the model fits the observed data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef2acc-ecd7-45a3-a1e2-5fa3b48259de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 2 \n",
    "\n",
    "\"Adjusted R-squared, often denoted as R²_adj, is a modification of the regular R-squared (R²) used in the context of linear regression. While both measures assess the goodness of fit of a regression model, adjusted R-squared takes into account the number of independent variables in the model, making it particularly useful for models with multiple predictors. The key difference between them lies in their treatment of model complexity. Regular R-squared simply measures the proportion of variance in the dependent variable explained by the independent variables, without considering how many variables are included. In contrast, adjusted R-squared penalizes the inclusion of unnecessary independent variables, helping to prevent overfitting. It achieves this by adjusting R² based on the number of predictors and the sample size, yielding a more balanced evaluation of the model's quality. Adjusted R-squared values can be negative when the model doesn't fit the data as well as a simple horizontal line, whereas regular R-squared values range from 0 to 1. Researchers often prefer adjusted R-squared when selecting the best model, as it provides a more robust measure of a model's effectiveness while accounting for its complexity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5452035-c4b2-48e3-ae92-8f2974735ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3 \n",
    "\n",
    "\"it is better to use Adjusted R-squared when there are multiple variables in the regression model. This would allow us to compare models with differing numbers of independent variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e54ac-21bd-4f54-bb01-b2d5c538fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 4 \n",
    "\n",
    "'''\n",
    "Mean Squared Error (MSE):\n",
    "Calculation: MSE is calculated by taking the average of the squared differences between the actual (observed) values and the predicted values. It's the sum of the squared residuals divided by the number of data points.\n",
    "Formula: MSE = (1/n) * Σ(actual - predicted)^2, where n is the number of data points.\n",
    "Interpretation: MSE measures the average squared difference between predicted and actual values. It punishes larger errors more severely due to the squaring of differences.\n",
    "\n",
    "Root Mean Squared Error (RMSE):\n",
    "Calculation: RMSE is the square root of the MSE. It's used to convert the error metric back to the same units as the original data.\n",
    "Formula: RMSE = √(MSE)\n",
    "Interpretation: RMSE provides a measure of the standard deviation of the residuals (prediction errors). It is more interpretable than MSE because it's in the same units as the dependent variable, making it easier to compare to the original data.\n",
    "\n",
    "Mean Absolute Error (MAE):\n",
    "Calculation: MAE is calculated by taking the average of the absolute differences between the actual and predicted values.\n",
    "Formula: MAE = (1/n) * Σ|actual - predicted|\n",
    "Interpretation: MAE measures the average absolute difference between predicted and actual values. Unlike MSE, it does not square the errors, so it does not punish large errors as severely. It provides a more robust measure of model performance when dealing with outliers.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0a12a-1490-4e4e-b7de-d2bde67049c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 5 \n",
    "\n",
    "\"Using RMSE, MSE, and MAE as evaluation metrics in regression analysis offers several advantages and disadvantages. These metrics provide a quantitative assessment of a model's predictive performance, making them widely adopted and easy to understand in the field. RMSE and MSE, in particular, are sensitive to larger errors, which can be advantageous when outliers are of significant concern. RMSE also provides an interpretable measure in the same units as the dependent variable. On the other hand, MAE is less sensitive to outliers, making it a more robust choice in the presence of extreme values or noisy data. However, these metrics have their drawbacks. RMSE and MSE can be heavily influenced by outliers, potentially providing a skewed view of model performance. MAE may lack proper weighting when different errors have varying consequences. Additionally, none of these metrics provide clear thresholds for what constitutes good or bad performance, and they may not account for the trade-off between bias and variance. Therefore, the choice of metric depends on the specific characteristics of the data and the goals of the analysis, and it is often recommended to consider multiple metrics and apply domain knowledge when evaluating regression models.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874853cc-db67-486c-aacf-f00588482306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 9 \n",
    "\n",
    "\"Model B (MAE of 8) may be chosen as the better performer if robustness to outliers is a priority. However, there are limitations to both metrics. RMSE is sensitive to outliers, which can distort its evaluation in the presence of extreme values. MAE, while more robust to outliers, may not provide insight into the severity of larger errors.\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
